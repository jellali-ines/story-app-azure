# ===================================
# Dockerfile pour AI Backend Flask avec Monitoring
# Note: Ollama doit tourner dans un conteneur s√©par√©
# ===================================
FROM python:3.9-slim

WORKDIR /app

# Installer les d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copier requirements.txt et installer
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# üëá COPIER LES FICHIERS PYTHON
COPY app.py .
COPY monitoring.py .

# Exposer le port
EXPOSE 5002

# Variables d'environnement
ENV FLASK_ENV=production
ENV PYTHONUNBUFFERED=1
# ‚ö†Ô∏è Ollama doit √™tre accessible via r√©seau Docker ou externe
ENV OLLAMA_URL=http://ollama:11434/api/generate
ENV MODEL_NAME=llama2-7b-mini

# Healthcheck
HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 \
  CMD curl -f http://localhost:5002/api/health || exit 1

# D√©marrer l'application
CMD ["python", "app.py"]